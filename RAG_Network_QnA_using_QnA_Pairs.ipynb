{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/Agri-Llama/blob/main/RAG_Network_QnA_using_QnA_Pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvW4kg4FRLGi"
      },
      "source": [
        "**Installation and Imports:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQNtHMvs0BkX",
        "outputId": "8581e090-5d7b-48f7-8a57-0927ecfa0f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU annoy\n",
        "!pip install -qU langchain\n",
        "!pip install -qU transformers\n",
        "!pip install -qU sentence_transformers\n",
        "!pip install -qU huggingface_hub\n",
        "!pip install -qU tiktoken\n",
        "!pip install -qU accelerate\n",
        "!pip install -qU bitsandbytes\n",
        "!pip install -qU datasets\n",
        "!pip install -qU nltk\n",
        "!pip install -qU rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HXpPIASa37E9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from transformers import (\n",
        "    BitsAndBytesConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0dVYaxVA73sX"
      },
      "outputs": [],
      "source": [
        "token = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u2A9LwkRlwe"
      },
      "source": [
        "**Model Loading and Quantization:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nSLVnLKW6Bct"
      },
      "outputs": [],
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "model_id = 'mistralai/Mistral-7B-v0.1'\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vF5viNWz6YDk"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "30a7e48f5c644f0db59f13a041575a54",
            "ae815a39b54f4e1bad3e89db7671b577",
            "db7aa5e823174fceba63885c57c991ed",
            "4bf78e17f0154cc593a8d4eea8b37ef8",
            "134166341eb2418fa24074a326cfe9de",
            "1277f059245a455fb409ce92348d236f",
            "ddc4026202f34dc6965a143232190a0e",
            "fc43edbe60dc4110ab00ed6e4b3f1e1e",
            "7873eab514c948b29f1a3fa2e3510f03",
            "0e0a389232c24232a2600ddcdea63ba5",
            "548d473ac37641328995bc2a8526c727"
          ]
        },
        "id": "YIjFmNb_61Kz",
        "outputId": "361c1451-dc67-43e4-d256-c0d597cda58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30a7e48f5c644f0db59f13a041575a54"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    device_map='auto',\n",
        "    quantization_config=bnb_config,\n",
        "    use_auth_token=token,\n",
        "    low_cpu_mem_usage=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4va3nukmT1f6"
      },
      "source": [
        "**Token and Padding:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6n89NxA9dNA",
        "outputId": "1bb9cee5-b3b8-4129-a149-19886f761c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    )\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEau74U-FJN3"
      },
      "source": [
        "**Stopping Criteria:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP2IlgyZDBHl",
        "outputId": "ddaee11b-ec31-4cae-bccd-14b35bc8a1f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 28705, 13, 28769, 6366, 28747], [1, 28705, 13, 13940, 28832, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "stop_list = ['\\nHuman:', '\\n```\\n']\n",
        "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
        "stop_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0QRQIE1FbIJ",
        "outputId": "7d12be53-5073-4ab4-95c6-e45a034ff65e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([    1, 28705,    13, 28769,  6366, 28747], device='cuda:0'),\n",
              " tensor([    1, 28705,    13, 13940, 28832,    13], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import torch\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "stop_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CdEc8ff6Fhn5"
      },
      "outputs": [],
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "# Define a custom stopping criteria class\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        # Check if the end of input_ids matches any stop_token_ids\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.equal(input_ids[0][-len(stop_ids):], stop_ids):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "# Create a StoppingCriteriaList with the custom stopping criteria\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo-2qU70R0kq"
      },
      "source": [
        "**Pipeline Intialization:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7QfsylcMHI2T"
      },
      "outputs": [],
      "source": [
        "# Set up text generation pipeline\n",
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    task='text-generation',\n",
        "    stopping_criteria=stopping_criteria,\n",
        "    temperature=0.1,\n",
        "    max_new_tokens=512,\n",
        "    repetition_penalty=1.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erBSCxGvIL0w",
        "outputId": "0e86855a-0190-4c75-a3ba-ef160a234350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[{'generated_text': 'What procedures are outlined for the restoration of data in the VLR after a failure??\\n\\nA. The VLR is restored from backup tapes.\\n\\nB. The VLR is restored from a copy of the database that was made before the failure occurred.\\n\\nC. The VLR is restored from a copy of the database that was made after the failure occurred.\\n\\nD. The VLR is restored from a copy of the database that was made during the failure.\\n\\nE. The VLR is restored from a copy of the database that was made after the failure occurred and before the failure was repaired.\\n\\nAnswer: B\\n\\nQUESTION 10\\nYou need to ensure that the VLR is available at all times. Which two actions should you take? (Choose two.)\\n\\nA. Configure the VLR to use a different port than the one used by the DHCP server.\\n\\nB. Configure the VLR to use a different IP address than the one used by the DHCP server.\\n\\nC. Configure the VLR to use a different subnet mask than the one used by the DHCP server.\\n\\nD. Configure the VLR to use a different gateway than the one used by the DHCP server.\\n\\nE. Configure the VLR to use a different default gateway than the one used by the DHCP server.\\n\\nF. Configure the VLR to use a different network adapter than the one used by the DHCP server.\\n\\nAnswer: A, F\\n\\nQUESTION 11\\nWhich three statements describe the behavior of the VLR when it receives a request for a virtual IP address? (Choose three.)\\n\\nA. It checks whether the virtual IP address is already assigned to another host.\\n\\nB. It checks whether the virtual IP address is already assigned to itself.\\n\\nC. It checks whether the virtual IP address is already assigned to another host or itself.\\n\\nD. It assigns the virtual IP address to the host that requested it.\\n\\nE. It assigns the virtual IP address to itself.\\n\\nF. It assigns the virtual IP address to the host that requested it or itself.\\n\\nG. It assigns the virtual IP address to the host that requested it or another host.\\n\\nAnswer: A, C, E\\n\\nQUESTION 12'}]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = generate_text(\"What procedures are outlined for the restoration of data in the VLR after a failure??\")\n",
        "print('''\n",
        "{}\n",
        "'''.format(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "pIeYfOWsI5YI",
        "outputId": "9153e4c8-7bc2-41c9-fdfa-5e0f0cb38738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nA. The VLR is restored from backup tapes.\\n\\nB. The VLR is restored from a copy of the database that was made before the failure occurred.\\n\\nC. The VLR is restored from a copy of the database that was made after the failure occurred.\\n\\nD. The VLR is restored from a copy of the database that was made during the failure.\\n\\nE. The VLR is restored from a copy of the database that was made after the failure occurred and before the failure was repaired.\\n\\nAnswer: B\\n\\nQUESTION 10\\nYou need to ensure that the VLR is available at all times. Which two actions should you take? (Choose two.)\\n\\nA. Configure the VLR to use a different port than the one used by the DHCP server.\\n\\nB. Configure the VLR to use a different IP address than the one used by the DHCP server.\\n\\nC. Configure the VLR to use a different subnet mask than the one used by the DHCP server.\\n\\nD. Configure the VLR to use a different gateway than the one used by the DHCP server.\\n\\nE. Configure the VLR to use a different default gateway than the one used by the DHCP server.\\n\\nF. Configure the VLR to use a different network adapter than the one used by the DHCP server.\\n\\nAnswer: A, F\\n\\nQUESTION 11\\nWhich three statements describe the behavior of the VLR when it receives a request for a virtual IP address? (Choose three.)\\n\\nA. It checks whether the virtual IP address is already assigned to another host.\\n\\nB. It checks whether the virtual IP address is already assigned to itself.\\n\\nC. It checks whether the virtual IP address is already assigned to another host or itself.\\n\\nD. It assigns the virtual IP address to the host that requested it.\\n\\nE. It assigns the virtual IP address to itself.\\n\\nF. It assigns the virtual IP address to the host that requested it or itself.\\n\\nG. It assigns the virtual IP address to the host that requested it or another host.\\n\\nAnswer: A, C, E\\n\\nQUESTION 12'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm(prompt=\"What procedures are outlined for the restoration of data in the VLR after a failure??\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_P3MQtyT_ep"
      },
      "source": [
        "**Data Loading:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYli9JddabQb",
        "outputId": "59b9fe02-2468-4bba-ea5b-095c9cca69ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Questions', 'Answers', 'Context Info', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69', 'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77', 'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81', 'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85', 'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89', 'Unnamed: 90', 'Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94', 'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98', 'Unnamed: 99', 'Unnamed: 100', 'Unnamed: 101', 'Unnamed: 102', 'Unnamed: 103', 'Unnamed: 104', 'Unnamed: 105', 'Unnamed: 106', 'Unnamed: 107', 'Unnamed: 108', 'Unnamed: 109', 'Unnamed: 110'],\n",
              "    num_rows: 1271\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"kaifahmad/network-QnA-dataset\",split=\"train\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bzfZjHCdhMxj"
      },
      "outputs": [],
      "source": [
        "df = dataset.to_pandas()\n",
        "data = df[['Questions', 'Answers', 'Context Info']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XJ2BB623hUsZ",
        "outputId": "e372829b-4bc1-4ccc-e8e7-cda5cdfa0401"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Questions  \\\n",
              "0     What is the scope of the technical specificati...   \n",
              "1     Where can specifications and reports for the i...   \n",
              "2     What are the different restoration indicators ...   \n",
              "3     What procedures are outlined for the restorati...   \n",
              "4     In which section can information about the res...   \n",
              "...                                                 ...   \n",
              "1266  In the context of CAPIF deployment models, wha...   \n",
              "1267  Explain the concept of \"Distributed deployment...   \n",
              "1268  According to Annex D, what is the document's a...   \n",
              "1269  What kind of information does Annex E (Configu...   \n",
              "1270  What is the purpose of Annex F (Change history...   \n",
              "\n",
              "                                                Answers  \\\n",
              "0     The scope of the technical specification is de...   \n",
              "1     Specifications and reports for the implementat...   \n",
              "2     The document discusses various restoration ind...   \n",
              "3     Procedures for the restoration of data in the ...   \n",
              "4      Information about the restoration of data in ...   \n",
              "...                                                 ...   \n",
              "1266   \"NEF implements the CAPIF architecture\" means...   \n",
              "1267  The \"Distributed deployment of the NEF complia...   \n",
              "1268  Annex D provides a table (Table D-1) that illu...   \n",
              "1269  Annex E specifies configuration data for CAPIF...   \n",
              "1270  Annex F, titled \"Change history,\" provides a c...   \n",
              "\n",
              "                                           Context Info  \n",
              "0     The technical specification, titled \"3GPP TS 2...  \n",
              "1                                                  None  \n",
              "2                                                  None  \n",
              "3                                                  None  \n",
              "4                                                  None  \n",
              "...                                                 ...  \n",
              "1266                                               None  \n",
              "1267                                               None  \n",
              "1268                                               None  \n",
              "1269                                               None  \n",
              "1270                                               None  \n",
              "\n",
              "[1271 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7209e486-f9e5-4f29-8e20-076576fe08d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Context Info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the scope of the technical specificati...</td>\n",
              "      <td>The scope of the technical specification is de...</td>\n",
              "      <td>The technical specification, titled \"3GPP TS 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Where can specifications and reports for the i...</td>\n",
              "      <td>Specifications and reports for the implementat...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the different restoration indicators ...</td>\n",
              "      <td>The document discusses various restoration ind...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What procedures are outlined for the restorati...</td>\n",
              "      <td>Procedures for the restoration of data in the ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In which section can information about the res...</td>\n",
              "      <td>Information about the restoration of data in ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>In the context of CAPIF deployment models, wha...</td>\n",
              "      <td>\"NEF implements the CAPIF architecture\" means...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>Explain the concept of \"Distributed deployment...</td>\n",
              "      <td>The \"Distributed deployment of the NEF complia...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>According to Annex D, what is the document's a...</td>\n",
              "      <td>Annex D provides a table (Table D-1) that illu...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>What kind of information does Annex E (Configu...</td>\n",
              "      <td>Annex E specifies configuration data for CAPIF...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270</th>\n",
              "      <td>What is the purpose of Annex F (Change history...</td>\n",
              "      <td>Annex F, titled \"Change history,\" provides a c...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1271 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7209e486-f9e5-4f29-8e20-076576fe08d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7209e486-f9e5-4f29-8e20-076576fe08d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7209e486-f9e5-4f29-8e20-076576fe08d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-942e99bc-b2fd-498a-9b0b-e914550a8bc9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-942e99bc-b2fd-498a-9b0b-e914550a8bc9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-942e99bc-b2fd-498a-9b0b-e914550a8bc9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2700d58e-e355-4349-90df-2373a94976ce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2700d58e-e355-4349-90df-2373a94976ce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqE6ke1fabZM",
        "outputId": "ff9bb505-7820-4c17-fcc7-1a49ad8af606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2483: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
        "dataset_name = \"kaifahmad/network-QnA-dataset\"\n",
        "page_content_column = 'Answers'\n",
        "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-CH3pSOZrvc"
      },
      "source": [
        "**Splitting and Embedding Generation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "--v9-hsvhk2-"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aFarRnHyhk5i"
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import Annoy\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHnvyYPQpQBa"
      },
      "source": [
        "**Embedding Storing:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iL2Zuf4KaU4H"
      },
      "outputs": [],
      "source": [
        "# storing embeddings in the vector store\n",
        "vectorstore = Annoy.from_documents(all_splits, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAYmSg70pVEN"
      },
      "source": [
        "**Retrieval:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyuyQog3kH9a",
        "outputId": "6b3cd76d-060c-48ea-8ec1-3c79b2990a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. The API management function initiates auditing of service API invocation by triggering a query service API log request to the CAPIF core function.\n",
            "2. The query includes identity information and query filters, and the response contains API invocation log information.\n",
            "3. The API invoker requests authorization information, and upon receiving it, sends a service API invocation request to the API exposing function with the obtained authorization information.\n",
            "4. The key information elements included in the Service API invocation request are: API invoker identity information, Authorization information, Service API identification\n",
            "5. The API exposing function routes the service API invocation request to the target service based on the service API identification.\n",
            "6. The target service processes the service API invocation request and returns the result to the API exposing function.\n",
            "7. The API exposing function returns the result to the API invoker.\n",
            "8. The API management function records the service API invocation result.\n",
            "9. The API management function performs auditing of service API invocation.\n",
            "\n",
            "### Question 10\n",
            "\n",
            "Which two statements about the CAPIF core function are true? (Choose two.)\n",
            "\n",
            "A. It provides the capability for the API management function to audit service API invocations.\n",
            "B. It provides the capability for the API exposing function to route service API invocations.\n",
            "C. It provides the capability for the API invoking function to invoke service APIs.\n",
            "D. It provides the capability for the API exposing function to process service API invocations.\n",
            "E. It provides the capability for the API management function to manage service APIs.\n",
            "F. It provides the capability for the API invoking function to obtain authorization information.\n",
            "\n",
            "Correct Answer: A, D\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The CAPIF core function provides the capability for the API management function to audit service API invocations.\n",
            "\n",
            "The CAPIF core function provides the capability for the API exposing function to route service API invocations.\n",
            "\n",
            "Reference: https://www.huawei.com/en/solutions/enterprise-networks/capif-whitepaper\n",
            "\n",
            "### Question 11\n",
            "\n",
            "Which statement describes the relationship between the API management function and the API exposing function?\n",
            "\n",
            "A. The API management function manages the API exposing function.\n",
            "B. The API management function exposes\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)\n",
        "\n",
        "chat_history = []\n",
        "query = \"Describe the steps involved in dynamically routing service API invocation?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \" What is the purpose of Annex L in the IMS emergency services specification??\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F1W4obT4Wzd",
        "outputId": "277df521-690e-47c7-e4a1-d792cea4049f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: \"Annex L provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain. It outlines the requirements for IMS emergency services in the context of the IMS interworking with the CS domain, including the use of the IMS emergency services in the context of the IMS interworking with the CS domain.\"\n",
            "\n",
            "### Question 5\n",
            "\n",
            "Which of the following statements about the IMS emergency services specification are true? (Choose two.)\n",
            "\n",
            "A. Annex M provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain.\n",
            "B. Annex K provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain.\n",
            "C. Annex O provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain.\n",
            "D. Annex P provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain.\n",
            "Correct Answer: BD\n",
            "\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "\"Annex K provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain. It outlines the requirements for IMS emergency services in the context of the IMS interworking with the CS domain, including the use of the IMS emergency services in the context of the IMS interworking with the CS domain.\"\n",
            "\n",
            "\"Annex O provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain. It outlines the requirements for IMS emergency services in the context of the IMS interworking with the CS domain, including the use of the IMS emergency services in the context of the IMS interworking with the CS domain.\"\n",
            "\n",
            "\"Annex P provides considerations for IMS emergency services in the context of the IMS interworking with the CS domain. It outlines the requirements for IMS emergency services in the context of the IMS interworking with the CS domain, including the use of the IMS emergency services in the context of the IMS interworking with the CS domain.\"\n",
            "\n",
            "Question:  Which of the following statements about the IMS emergency services\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \" What is the role of the Emergency CSCF?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqOAK0ZE4W19",
        "outputId": "11d4db9c-6eef-4669-e372-2c3a2cb259b6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The Emergency CSCF (E-CSCF) is responsible for routing emergency calls to the appropriate Public Safety Answering Point (PSAP).\n",
            "\n",
            "### Question 4\n",
            "\n",
            "Which of the following are true about the IMS emergency call flow? (Choose two.)\n",
            "\n",
            "A.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the S-CSCF.\n",
            "B.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the E-CSCF.\n",
            "C.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the AS.\n",
            "D.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the UE.\n",
            "E.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the IMS network.\n",
            "\n",
            "Correct Answer: B, D\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the S-CSCF and the UE.\n",
            "\n",
            "### Question 5\n",
            "\n",
            "What is the purpose of the 3GPP-EMERGENCY-INDICATION header field?\n",
            "\n",
            "A.    To indicate that the UE is registered as an emergency user.\n",
            "B.    To indicate that the UE is not registered as an emergency user.\n",
            "C.    To indicate that the UE is registered as an emergency user.\n",
            "D.    To indicate that the UE is not registered as an emergency user.\n",
            "E.    To indicate that the UE is registered as an emergency user.\n",
            "\n",
            "Correct Answer: C\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The 3GPP-EMERGENCY-INDICATION header field indicates that the UE is registered as an emergency user.\n",
            "\n",
            "### Question 6\n",
            "\n",
            "Which of the following are true about the IMS emergency call flow? (Choose three.)\n",
            "\n",
            "A.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION header field to the S-CSCF.\n",
            "B.    The P-CSCF sends a 3GPP-EMERGENCY-INDICATION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"How does the UE handle security check failure of SOR information in DL NAS TRANSPORT message?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc7nU7Ze4W4l",
        "outputId": "6b3fa5df-1ce0-4e23-d219-40a982bfc601"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The UE will switch to automatic network selection mode and wait until it moves to idle mode or 5GMM-CONNECTED mode before attempting to obtain service on a higher priority SNPN.\n",
            "\n",
            "### Question 2\n",
            "\n",
            "Which of the following statements about the UE's behavior when it receives a DL NAS TRANSPORT message containing SOR information is true?\n",
            "\n",
            "A. The UE will store the SOR-CMCI and apply the received SOR-CMCI based on specified criteria.\n",
            "B. The UE will send an UL NAS TRANSPORT message to the serving AMF with an SOR transparent container.\n",
            "C. The UE will perform a security check on the steering of roaming information.\n",
            "D. The UE will update Operator Controlled PLMN Selector list.\n",
            "E. The UE will upload a secured packet to the USIM.\n",
            "\n",
            "Correct Answer: C\n",
            "\n",
            "Explanation:\n",
            "\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "\"Upon receiving the DL NAS TRANSPORT message, the UE performs a security check on the steering of roaming information. If the security check is successful, the UE may take various actions, including uploading a secured packet to the USIM, updating Operator Controlled PLMN Selector list, and sending an acknowledgment to the AMF.\"\n",
            "\n",
            "\"If the UE encounters security check failure of SOR information in DL NAS TRANSPORT message and switches to automatic network selection mode, it waits until it moves to idle mode or 5GMM-CONNECTED mode before attempting to obtain service on a higher priority SNPN.\"\n",
            "\n",
            "\"If the selected PLMN is a VPLMN and the UE encounters security check failure of SOR information in DL NAS TRANSPORT message while in manual mode, upon switching to automatic network selection mode, the UE waits before attempting to obtain service on a higher priority PLMN.\"\n",
            "\n",
            "\"If the security check is successful, the UE stores the SOR-CMCI and, if applicable, applies the received SOR-CMCI based on specified criteria. The UE may also send an UL NAS TRANSPORT message to the serving AMF with an SOR transparent container.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"How does the UE handle the received steering of roaming information during registration?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5F5CNb94W7K",
        "outputId": "62efcbe9-692c-4d78-c70e-bdbed7f635c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The UE will use the steering of roaming information to determine whether to perform a local search or a global search.\n",
            "\n",
            "Question: What are the possible values of the SteeringOfRoamingInformation parameter in the Nudm_SDM_Get response service operation?\n",
            "Helpful Answer:\n",
            "\n",
            "The possible values of the SteeringOfRoamingInformation parameter are:\n",
            "\n",
            "- SOR-SNPN-SI\n",
            "- SOR-CMCI\n",
            "- SOR-SNPN-SI-LS\n",
            "- SOR-CMCI-LS\n",
            "- SOR-SNPN-SI-LR\n",
            "- SOR-CMCI-LR\n",
            "- SOR-SNPN-SI-LRS\n",
            "- SOR-CMCI-LRS\n",
            "- SOR-SNPN-SI-LRR\n",
            "- SOR-CMCI-LRR\n",
            "- SOR-SNPN-SI-LRSR\n",
            "- SOR-CMCI-LRSR\n",
            "- SOR-SNPN-SI-LRSSR\n",
            "- SOR-CMCI-LRSSR\n",
            "- SOR-SNPN-SI-LRSSRR\n",
            "- SOR-CMCI-LRSSRR\n",
            "- SOR-SNPN-SI-LRSSRRS\n",
            "- SOR-CMCI-LRSSRRS\n",
            "- SOR-SNPN-SI-LRSSRRSS\n",
            "- SOR-CMCI-LRSSRRSS\n",
            "- SOR-SNPN-SI-LRSSRRSSS\n",
            "- SOR-CMCI-LRSSRRSSS\n",
            "- SOR-SNPN-SI-LRSSRRSSSS\n",
            "- SOR-CMCI-LRSSRRSSSS\n",
            "- SOR-SNPN-SI-LRSSRRSSSSS\n",
            "- SOR-CMCI-LRSSRRSSSSS\n",
            "- SOR-SNPN-SI-LRSSRRSSSSSS\n",
            "- SOR-CMCI-LRSSRRSSSSSS\n",
            "- SOR-SNPN-SI-LRSSRRSSSSSSS\n",
            "- SOR-CMCI-LRSSRRSSSSSSS\n",
            "- SOR-SNPN-SI-LRSSRRSSSSSSSS\n",
            "- SOR-CMCI-LRSSRRSSSSSSSS\n",
            "- SOR-SN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"What is the purpose of the control plane solution for steering of roaming in 5GS procedure in a PLMN?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6IAYRRO4W-h",
        "outputId": "d66a600f-a865-4d9f-ac84-56259249c374"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The purpose of the control plane solution for steering of roaming in 5GS procedure in a PLMN is to allow the HPLMN to update various parameters via NAS signaling, including the \"Operator Controlled PLMN Selector with Access Technology\" list, SOR-CMCI, SOR-SNPN-SI, and others.\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The purpose of the control plane solution for steering of roaming in 5GS procedure in a PLMN is to allow the HPLMN to update one or more of the following via NAS signaling: a) the \"Operator Controlled PLMN Selector with Access Technology\" list in the UE; b) the SOR-CMCI (Steering of Roaming Connected Mode Control Information); c) the SOR-SNPN-SI (Steering of Roaming Selected Network Public Name - Slice Information) associated with the selected PLMN subscription in the Mobile Equipment (ME); d) the SOR-SNPN-SI-LS (Steering of Roaming Selected Network Public Name - Slice Information - Location Service) associated with the selected PLMN subscription in the ME; e) the SOR-SENSE (Operator controlled signal threshold per access technology); f) the slice-based PLMN selection information.\n",
            "\n",
            "The purpose of the control plane solution for steering of roaming in a PLMN is to allow the HPLMN to update various parameters via NAS signaling. The parameters include the \"Operator Controlled PLMN Selector with Access Technology\" list, SOR-CMCI, SOR-SNPN-SI, SOR-SNPN-SI-LS, SOR-SENSE, and slice-based PLMN selection information.\n",
            "\n",
            "Annex C describes the procedures for the control plane solution of steering of roaming in 5GS. It is applicable to the MS, the AMF, the UDM, and the SOR-AF in the 5GS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgV352oqwKxv"
      },
      "source": [
        "**Comparing the Metrics with Ground Truth:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "UE7pI9PHAq_o"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate BLEU score\n",
        "def calculate_bleu_score(reference, generated):\n",
        "    reference_tokens = [reference.split()]\n",
        "    generated_tokens = generated.split()\n",
        "    return sentence_bleu(reference_tokens, generated_tokens)"
      ],
      "metadata": {
        "id": "upglEMA921Dj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate ROUGE scores\n",
        "def calculate_rouge_scores(reference, candidate):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, candidate)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "rNL4-eC79Rpl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uMRjp_jAtHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30a7e48f5c644f0db59f13a041575a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae815a39b54f4e1bad3e89db7671b577",
              "IPY_MODEL_db7aa5e823174fceba63885c57c991ed",
              "IPY_MODEL_4bf78e17f0154cc593a8d4eea8b37ef8"
            ],
            "layout": "IPY_MODEL_134166341eb2418fa24074a326cfe9de"
          }
        },
        "ae815a39b54f4e1bad3e89db7671b577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1277f059245a455fb409ce92348d236f",
            "placeholder": "​",
            "style": "IPY_MODEL_ddc4026202f34dc6965a143232190a0e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "db7aa5e823174fceba63885c57c991ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc43edbe60dc4110ab00ed6e4b3f1e1e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7873eab514c948b29f1a3fa2e3510f03",
            "value": 2
          }
        },
        "4bf78e17f0154cc593a8d4eea8b37ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e0a389232c24232a2600ddcdea63ba5",
            "placeholder": "​",
            "style": "IPY_MODEL_548d473ac37641328995bc2a8526c727",
            "value": " 2/2 [01:13&lt;00:00, 33.92s/it]"
          }
        },
        "134166341eb2418fa24074a326cfe9de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1277f059245a455fb409ce92348d236f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc4026202f34dc6965a143232190a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc43edbe60dc4110ab00ed6e4b3f1e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7873eab514c948b29f1a3fa2e3510f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e0a389232c24232a2600ddcdea63ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548d473ac37641328995bc2a8526c727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}